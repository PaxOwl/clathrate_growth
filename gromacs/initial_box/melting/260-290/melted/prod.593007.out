                   :-) GROMACS - gmx mdrun, VERSION 5.1.2 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra   Sebastian Fritsch 
  Gerrit Groenhof   Christoph Junghans   Anca Hamuraru    Vincent Hindriksen
 Dimitrios Karkoulis    Peter Kasson        Jiri Kraus      Carsten Kutzner  
    Per Larsson      Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff 
   Erik Marklund      Teemu Murtola       Szilard Pall       Sander Pronk   
   Roland Schulz     Alexey Shvetsov     Michael Shirts     Alfons Sijbers  
   Peter Tieleman    Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, VERSION 5.1.2
Executable:   /Softs/lumiere/gromacs/gcc/5.1.2/bin/gmx_mpi
Data prefix:  /Softs/lumiere/gromacs/gcc/5.1.2
Command line:
  gmx_mpi mdrun -s topol.tpr -g md.log -o traj.trr -c conf.gro


Back Off! I just backed up md.log to ./#md.log.1#

Number of logical cores detected (16) does not match the number reported by OpenMP (1).
Consider setting the launch configuration manually!

Running on 2 nodes with total 32 cores, 32 logical cores
  Cores per node:           16
  Logical cores per node:   16
Hardware detected on host node2-56 (the node of MPI rank 0):
  CPU info:
    Vendor: GenuineIntel
    Brand:  Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: SSE4.1

Compiled SIMD instructions: SSE4.1, GROMACS could use AVX2_256 on this machine, which is better

Reading file topol.tpr, VERSION 5.1.2 (single precision)
Changing nstlist from 10 to 20, rlist from 0.954 to 0.974

The number of OpenMP threads was set by environment variable OMP_NUM_THREADS to 1

Will use 24 particle-particle and 8 PME only ranks
This is a guess, check the performance at the end of the log file
Using 32 MPI processes
Using 1 OpenMP thread per MPI process


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up traj.trr to ./#traj.trr.1#

Back Off! I just backed up ener.edr to ./#ener.edr.2#
starting mdrun 'Methane in water'
20000000 steps,  20000.0 ps.

NOTE: Turning on dynamic load balancing


Writing final coordinates.

Back Off! I just backed up conf.gro to ./#conf.gro.2#

 Average load imbalance: 4.8 %
 Part of the total run time spent waiting due to load imbalance: 3.4 %
 Steps where the load balancing was limited by -rdd, -rcon and/or -dds: X 0 %
 Average PME mesh/force load: 0.468
 Part of the total run time spent waiting due to PP/PME imbalance: 11.0 %

NOTE: 11.0 % performance was lost because the PME ranks
      had less work to do than the PP ranks.
      You might want to decrease the number of PME ranks
      or decrease the cut-off and the grid spacing.


               Core t (s)   Wall t (s)        (%)
       Time:   498519.893    15581.793     3199.4
                         4h19:41
                 (ns/day)    (hour/ns)
Performance:      110.899        0.216

gcq#192: "Your Country Needs YOU" (U.S. Army)

